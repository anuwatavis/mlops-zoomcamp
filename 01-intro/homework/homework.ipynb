{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"Green Taxi Trip Records\", we'll use \"For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Download the data for January and February 2021.\n",
    "\n",
    "Note that you need \"For-Hire Vehicle Trip Records\", not \"High Volume For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Read the data for January. How many records are there?\n",
    "\n",
    "* 1054112\n",
    "* 1154112\n",
    "* 1254112\n",
    "* 1354112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory for save file from download\n",
    "Path.mkdir(Path.cwd() / \"data\", exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-21 22:27:04--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-01.parquet\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.217.82.108\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.217.82.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11886281 (11M) [binary/octet-stream]\n",
      "Saving to: ‘data/fhv_tripdata_2021-01.parquet.2’\n",
      "\n",
      "fhv_tripdata_2021-0 100%[===================>]  11.33M  4.61MB/s    in 2.5s    \n",
      "\n",
      "2022-05-21 22:27:08 (4.61 MB/s) - ‘data/fhv_tripdata_2021-01.parquet.2’ saved [11886281/11886281]\n",
      "\n",
      "--2022-05-21 22:27:08--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-02.parquet\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.217.82.108\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.217.82.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10645466 (10M) [binary/octet-stream]\n",
      "Saving to: ‘data/fhv_tripdata_2021-02.parquet.2’\n",
      "\n",
      "fhv_tripdata_2021-0 100%[===================>]  10.15M  4.30MB/s    in 2.4s    \n",
      "\n",
      "2022-05-21 22:27:12 (4.30 MB/s) - ‘data/fhv_tripdata_2021-02.parquet.2’ saved [10645466/10645466]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download  For-Hire Vehicle Trip Records taxi data from NYC taxi data for january and febuary 2021\n",
    "# January URL : https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-01.parquet\n",
    "# Febuary URL : https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-02.parquet \n",
    "JANUARY_URL = 'https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-01.parquet'\n",
    "FEBUARY_URL = 'https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-02.parquet'\n",
    "!wget $JANUARY_URL -P data/\n",
    "!wget $FEBUARY_URL -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_df = pd.read_parquet(Path.cwd() / \"data\" / \"fhv_tripdata_2021-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1154112 recoreds\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {jan_df.shape[0]} recoreds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the average trip duration in January?\n",
    "\n",
    "* 15.16\n",
    "* 19.16\n",
    "* 24.16\n",
    "* 29.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dispatching_base_num', 'pickup_datetime', 'dropOff_datetime',\n",
       "       'PUlocationID', 'DOlocationID', 'SR_Flag', 'Affiliated_base_number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duration \n",
    "jan_df['duration'] = jan_df.dropOff_datetime - jan_df.pickup_datetime\n",
    "jan_df.duration = jan_df.duration.apply(lambda td: td.total_seconds() / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.167224093791006"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan_df['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_df = jan_df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.154112e+06</td>\n",
       "      <td>1.154112e+06</td>\n",
       "      <td>1154112.0</td>\n",
       "      <td>1.154112e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.290294e+01</td>\n",
       "      <td>1.166559e+02</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.916722e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.123654e+01</td>\n",
       "      <td>8.848660e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.986922e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.666667e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.340000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53%</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.190000e+02</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.416667e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63%</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.650000e+02</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.713333e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73%</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.920000e+02</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.121667e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83%</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.250000e+02</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.763333e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.233710e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PUlocationID  DOlocationID    SR_Flag      duration\n",
       "count  1.154112e+06  1.154112e+06  1154112.0  1.154112e+06\n",
       "mean   2.290294e+01  1.166559e+02       -1.0  1.916722e+01\n",
       "std    6.123654e+01  8.848660e+01        0.0  3.986922e+02\n",
       "min   -1.000000e+00 -1.000000e+00       -1.0  1.666667e-02\n",
       "50%   -1.000000e+00  9.700000e+01       -1.0  1.340000e+01\n",
       "53%   -1.000000e+00  1.190000e+02       -1.0  1.416667e+01\n",
       "63%   -1.000000e+00  1.650000e+02       -1.0  1.713333e+01\n",
       "73%   -1.000000e+00  1.920000e+02       -1.0  2.121667e+01\n",
       "83%   -1.000000e+00  2.250000e+02       -1.0  2.763333e+01\n",
       "max    2.650000e+02  2.650000e+02       -1.0  4.233710e+05"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan_df.describe(percentiles=[0.53, 0.63, 0.73, 0.83])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Check the distribution of the duration variable. There are some outliers. \n",
    "\n",
    "Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "How many records did you drop? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_df = jan_df[(jan_df.duration >= 1) & (jan_df.duration <= 60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix? (The number of columns).\n",
    "\n",
    "* 2\n",
    "* 152\n",
    "* 352\n",
    "* 525\n",
    "* 725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined features\n",
    "features = ['PUlocationID', 'DOlocationID']\n",
    "# Convert PUlocationID and DOLocationID to str type\n",
    "jan_df[features] = jan_df[features].astype(str)\n",
    "\n",
    "# Turn the data frame into a list of dictionarires\n",
    "train_dicts = jan_df[features].to_dict(orient='records')\n",
    "\n",
    "# Fit a dirctionry vectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Target\n",
    "target = 'duration'\n",
    "y_train = jan_df[target].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 525 columns.\n"
     ]
    }
   ],
   "source": [
    "dv.get_feature_names_out()\n",
    "print(f'There are {X_train.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 5.52\n",
    "* 10.52\n",
    "* 15.52\n",
    "* 20.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.528519388232237"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "mean_squared_error(y_train, y_pred, squared=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (Feb 2021). \n",
    "\n",
    "What's the RMSE on validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load febuary dataframe\n",
    "feb_df = pd.read_parquet(Path.cwd() / \"data\" / \"fhv_tripdata_2021-02.parquet\")\n",
    "feb_df = feb_df.fillna(-1)\n",
    "# Get duration \n",
    "feb_df['duration'] = feb_df.dropOff_datetime - feb_df.pickup_datetime\n",
    "feb_df.duration = feb_df.duration.apply(lambda td: td.total_seconds() / 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_df = feb_df[(feb_df.duration >= 1) & (feb_df.duration <= 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined features\n",
    "features = ['PUlocationID', 'DOlocationID']\n",
    "# Convert PUlocationID and DOLocationID to str type\n",
    "feb_df[features] = feb_df[features].astype(str)\n",
    "\n",
    "# Turn the data frame into a list of dictionarires\n",
    "val_dicts = feb_df[features].to_dict(orient='records')\n",
    "\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "# Target\n",
    "target = 'duration'\n",
    "y_val = feb_df[target].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.014286813221993"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_val_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str)-> pd.DataFrame:\n",
    "    \"\"\"Load taxi data\n",
    "\n",
    "    Args:\n",
    "        filename (str): filename\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: taxi dataframe\n",
    "    \"\"\"   \n",
    "     \n",
    "    # Load data\n",
    "    df = pd.read_parquet(Path.cwd() / \"data\" / filename)\n",
    "    # Fill na value with - 1\n",
    "    df = df.fillna(-1)\n",
    "\n",
    "    # Create duration and calculate duration from dropoff and pickup time\n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    # Filter duration in range [1, 60]\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    # Defined features\n",
    "    features = ['PUlocationID', 'DOlocationID']\n",
    "    # Convert PUlocationID and DOLocationID to str type\n",
    "    df[features] = df[features].astype(str)\n",
    "\n",
    "    df = df[['PUlocationID', 'DOlocationID', 'duration']]\n",
    "\n",
    "    print(f\"\"\"Load data from {filename}\n",
    "        columns : {list(df.columns)}\n",
    "    \"\"\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_feature_and_target(df: pd.DataFrame, target_column: str, feature_columns):\n",
    "    \"\"\"Get feature and target dataframe from df input\n",
    "    \"\"\"\n",
    "    target_df = df[target_column].values\n",
    "    feature_df = df[feature_columns]\n",
    "\n",
    "    return (feature_df, target_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from fhv_tripdata_2021-01.parquet\n",
      "        columns : ['PUlocationID', 'DOlocationID', 'duration']\n",
      "    \n",
      "Load data from fhv_tripdata_2021-02.parquet\n",
      "        columns : ['PUlocationID', 'DOlocationID', 'duration']\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "train_df = load_data(\"fhv_tripdata_2021-01.parquet\")\n",
    "val_df = load_data(\"fhv_tripdata_2021-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X (Features), y (target)\n",
    "X_train, y_train = get_feature_and_target(train_df, 'duration', ['PUlocationID', 'DOlocationID'])\n",
    "X_val, y_val = get_feature_and_target(val_df, 'duration', ['PUlocationID', 'DOlocationID'])\n",
    "\n",
    "# Apply to_dict to dataframe\n",
    "X_train = X_train.to_dict(orient='records')\n",
    "X_val = X_val.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traning Model\n",
    "\n",
    "## Vectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(X_train)\n",
    "X_val = dv.transform(X_val)\n",
    "\n",
    "\n",
    "# Train model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Training dataset\n",
      "10.528519388232237\n",
      "\n",
      "Evaluation on validation dataset\n",
      "11.014286813221993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with valid dataset\n",
    "print(\"Evaluation on Training dataset\")\n",
    "y_train_pred = lr.predict(X_train)\n",
    "print(mean_squared_error(y_train, y_train_pred, squared=False), end=\"\\n\\n\")\n",
    "\n",
    "y_val_pred = lr.predict(X_val)\n",
    "print(\"Evaluation on validation dataset\")\n",
    "print(mean_squared_error(y_val, y_val_pred, squared=False), end=\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4097c64d94c5b44aa96706a47b357d91e727b3cbacdc6414ea202e6f06a3d71"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
